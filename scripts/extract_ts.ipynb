{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/fdjim/Desktop/PDS_CODE/src_acw_calculation_stats')\n",
    "\n",
    "from data_loader import load_fmri_data, load_regressors\n",
    "from roi_creation import fetch_aal_atlas, create_label_to_pseudo_index, get_pseudo_index, create_masker, extract_timeseries, extract_timeseries_for_roi\n",
    "from region_lists import auditory_cortex_regions, visual_cortex_regions, motor_cortex_regions, dmn_regions, fpn_regions, salience_network_regions, limbic_system_regions\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load empricial fMRI data and regressors\n",
    "data_dir = '/Users/fdjim/Desktop/PDS_FULL/derivatives/fmriprep'\n",
    "subjects = [\n",
    "    \"sub-003P\", \"sub-004P\", \"sub-005C\", \"sub-005P\", \"sub-006C\",\n",
    "    \"sub-007C\", \"sub-007P\", \"sub-008P\", \"sub-009C\", \"sub-010P\",\n",
    "    \"sub-013C\", \"sub-014C\", \"sub-014P\", \"sub-015C\", \"sub-015P\",\n",
    "    \"sub-016C\", \"sub-016P\", \"sub-017C\", \"sub-018C\", \"sub-018P\",\n",
    "    \"sub-019C\", \"sub-019P\", \"sub-020C\", \"sub-020P\", \"sub-021C\",\n",
    "    \"sub-023P\", \"sub-024C\", \"sub-024P\", \"sub-025C\", \"sub-026C\",\n",
    "    \"sub-027C\", \"sub-028C\", \"sub-029C\", \"sub-030C\", \"sub-030P\",\n",
    "    \"sub-031C\", \"sub-031P\", \"sub-032P\", \"sub-033P\", \"sub-035P\",\n",
    "    \"sub-037P\", \"sub-039P\", \"sub-041P\", \"sub-042P\", \"sub-043P\",\n",
    "    \"sub-045P\", \"sub-046P\", \"sub-047P\", \"sub-048P\", \"sub-049P\",\n",
    "    \"sub-050P\", \"sub-051P\", \"sub-052P\", \"sub-055P\", \"sub-056P\",\n",
    "    \"sub-061P\", \"sub-066P\", \"sub-067P\", \"sub-069P\", \"sub-071P\",\n",
    "    \"sub-075P\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC: ['sub-005C', 'sub-006C', 'sub-007C', 'sub-009C', 'sub-013C', 'sub-014C', 'sub-015C', 'sub-016C', 'sub-017C', 'sub-018C', 'sub-019C', 'sub-020C', 'sub-021C', 'sub-024C', 'sub-025C', 'sub-026C', 'sub-027C', 'sub-028C', 'sub-029C', 'sub-030C', 'sub-031C']\n",
      "MDD: ['sub-003P', 'sub-004P', 'sub-005P', 'sub-007P', 'sub-008P', 'sub-010P', 'sub-014P', 'sub-020P', 'sub-031P', 'sub-032P', 'sub-033P', 'sub-035P', 'sub-037P', 'sub-042P', 'sub-046P', 'sub-048P', 'sub-051P', 'sub-052P', 'sub-066P', 'sub-067P', 'sub-075P']\n",
      "SZ: ['sub-015P', 'sub-016P', 'sub-018P', 'sub-019P', 'sub-023P', 'sub-024P', 'sub-030P', 'sub-039P', 'sub-041P', 'sub-043P', 'sub-045P', 'sub-047P', 'sub-049P', 'sub-050P', 'sub-055P', 'sub-056P', 'sub-061P', 'sub-069P', 'sub-071P']\n"
     ]
    }
   ],
   "source": [
    "# Split the subjects into groups for the analysis\n",
    "diagnosis_df = pd.read_csv('/Users/fdjim/Desktop/PDS_FULL/participants.tsv', sep='\\t')\n",
    "# Create a dictionary mapping subject IDs to diagnosis\n",
    "diagnosis_dict = dict(zip(diagnosis_df['participant_id'], diagnosis_df['dx']))\n",
    "# Split subjects into groups based on diagnosis\n",
    "subjects_hc = []\n",
    "subjects_mdd = []\n",
    "subjects_sz = []\n",
    "for subject in subjects:\n",
    "    if subject in diagnosis_dict:\n",
    "        if diagnosis_dict[subject] == 'hc':\n",
    "            subjects_hc.append(subject)\n",
    "        elif diagnosis_dict[subject] == 'mdd':\n",
    "            subjects_mdd.append(subject)\n",
    "        elif diagnosis_dict[subject] == 'sz':\n",
    "            subjects_sz.append(subject)\n",
    "    else:\n",
    "        print(f\"Warning: Subject {subject} not found in diagnosis file\")\n",
    "print(f\"HC: {subjects_hc}\")\n",
    "print(f\"MDD: {subjects_mdd}\")\n",
    "print(f\"SZ: {subjects_sz}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch atlas and create label to pseudo-index mapping\n",
    "labels_aal, indices_aal, aal_img = fetch_aal_atlas()\n",
    "pseudo_idx_aal = create_label_to_pseudo_index(labels_aal)\n",
    "pseudo_idx_auditory = get_pseudo_index(pseudo_idx_aal, auditory_cortex_regions)\n",
    "pseudo_idx_visual = get_pseudo_index(pseudo_idx_aal, visual_cortex_regions)\n",
    "pseudo_idx_motor = get_pseudo_index(pseudo_idx_aal, motor_cortex_regions)\n",
    "pseudo_idx_dmn = get_pseudo_index(pseudo_idx_aal, dmn_regions)\n",
    "pseudo_idx_fpn = get_pseudo_index(pseudo_idx_aal, fpn_regions)\n",
    "pseudo_idx_salience = get_pseudo_index(pseudo_idx_aal, salience_network_regions)\n",
    "pseudo_idx_limbic = get_pseudo_index(pseudo_idx_aal, limbic_system_regions)\n",
    "\n",
    "pseudo_indices = [pseudo_idx_auditory, pseudo_idx_visual, pseudo_idx_motor, pseudo_idx_dmn, pseudo_idx_fpn, pseudo_idx_salience, pseudo_idx_limbic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2001', '2002', '2101', '2102', '2111', '2112', '2201', '2202', '2211', '2212', '2301', '2302', '2311', '2312', '2321', '2322', '2331', '2332', '2401', '2402', '2501', '2502', '2601', '2602', '2611', '2612', '2701', '2702', '3001', '3002', '4001', '4002', '4011', '4012', '4021', '4022', '4101', '4102', '4111', '4112', '4201', '4202', '5001', '5002', '5011', '5012', '5021', '5022', '5101', '5102', '5201', '5202', '5301', '5302', '5401', '5402', '6001', '6002', '6101', '6102', '6201', '6202', '6211', '6212', '6221', '6222', '6301', '6302', '6401', '6402', '7001', '7002', '7011', '7012', '7021', '7022', '7101', '7102', '8101', '8102', '8111', '8112', '8121', '8122', '8201', '8202', '8211', '8212', '8301', '8302', '9001', '9002', '9011', '9012', '9021', '9022', '9031', '9032', '9041', '9042', '9051', '9052', '9061', '9062', '9071', '9072', '9081', '9082', '9100', '9110', '9120', '9130', '9140', '9150', '9160', '9170']\n",
      "['Precentral_L', 'Precentral_R', 'Frontal_Sup_L', 'Frontal_Sup_R', 'Frontal_Sup_Orb_L', 'Frontal_Sup_Orb_R', 'Frontal_Mid_L', 'Frontal_Mid_R', 'Frontal_Mid_Orb_L', 'Frontal_Mid_Orb_R', 'Frontal_Inf_Oper_L', 'Frontal_Inf_Oper_R', 'Frontal_Inf_Tri_L', 'Frontal_Inf_Tri_R', 'Frontal_Inf_Orb_L', 'Frontal_Inf_Orb_R', 'Rolandic_Oper_L', 'Rolandic_Oper_R', 'Supp_Motor_Area_L', 'Supp_Motor_Area_R', 'Olfactory_L', 'Olfactory_R', 'Frontal_Sup_Medial_L', 'Frontal_Sup_Medial_R', 'Frontal_Med_Orb_L', 'Frontal_Med_Orb_R', 'Rectus_L', 'Rectus_R', 'Insula_L', 'Insula_R', 'Cingulum_Ant_L', 'Cingulum_Ant_R', 'Cingulum_Mid_L', 'Cingulum_Mid_R', 'Cingulum_Post_L', 'Cingulum_Post_R', 'Hippocampus_L', 'Hippocampus_R', 'ParaHippocampal_L', 'ParaHippocampal_R', 'Amygdala_L', 'Amygdala_R', 'Calcarine_L', 'Calcarine_R', 'Cuneus_L', 'Cuneus_R', 'Lingual_L', 'Lingual_R', 'Occipital_Sup_L', 'Occipital_Sup_R', 'Occipital_Mid_L', 'Occipital_Mid_R', 'Occipital_Inf_L', 'Occipital_Inf_R', 'Fusiform_L', 'Fusiform_R', 'Postcentral_L', 'Postcentral_R', 'Parietal_Sup_L', 'Parietal_Sup_R', 'Parietal_Inf_L', 'Parietal_Inf_R', 'SupraMarginal_L', 'SupraMarginal_R', 'Angular_L', 'Angular_R', 'Precuneus_L', 'Precuneus_R', 'Paracentral_Lobule_L', 'Paracentral_Lobule_R', 'Caudate_L', 'Caudate_R', 'Putamen_L', 'Putamen_R', 'Pallidum_L', 'Pallidum_R', 'Thalamus_L', 'Thalamus_R', 'Heschl_L', 'Heschl_R', 'Temporal_Sup_L', 'Temporal_Sup_R', 'Temporal_Pole_Sup_L', 'Temporal_Pole_Sup_R', 'Temporal_Mid_L', 'Temporal_Mid_R', 'Temporal_Pole_Mid_L', 'Temporal_Pole_Mid_R', 'Temporal_Inf_L', 'Temporal_Inf_R', 'Cerebelum_Crus1_L', 'Cerebelum_Crus1_R', 'Cerebelum_Crus2_L', 'Cerebelum_Crus2_R', 'Cerebelum_3_L', 'Cerebelum_3_R', 'Cerebelum_4_5_L', 'Cerebelum_4_5_R', 'Cerebelum_6_L', 'Cerebelum_6_R', 'Cerebelum_7b_L', 'Cerebelum_7b_R', 'Cerebelum_8_L', 'Cerebelum_8_R', 'Cerebelum_9_L', 'Cerebelum_9_R', 'Cerebelum_10_L', 'Cerebelum_10_R', 'Vermis_1_2', 'Vermis_3', 'Vermis_4_5', 'Vermis_6', 'Vermis_7', 'Vermis_8', 'Vermis_9', 'Vermis_10']\n"
     ]
    }
   ],
   "source": [
    "print(indices_aal)\n",
    "print(labels_aal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Auditory Network Regions:\n",
      "- Heschl_L\n",
      "- Heschl_R\n",
      "- Temporal_Sup_L\n",
      "- Temporal_Sup_R\n",
      "\n",
      "Visual Network Regions:\n",
      "- Calcarine_L\n",
      "- Calcarine_R\n",
      "- Cuneus_L\n",
      "- Cuneus_R\n",
      "- Lingual_L\n",
      "- Lingual_R\n",
      "- Occipital_Sup_L\n",
      "- Occipital_Sup_R\n",
      "- Occipital_Mid_L\n",
      "- Occipital_Mid_R\n",
      "\n",
      "Motor Network Regions:\n",
      "- Precentral_L\n",
      "- Precentral_R\n",
      "- Supp_Motor_Area_L\n",
      "- Supp_Motor_Area_R\n",
      "\n",
      "DMN Network Regions:\n",
      "- Frontal_Sup_Medial_L\n",
      "- Frontal_Sup_Medial_R\n",
      "- Cingulum_Post_L\n",
      "- Cingulum_Post_R\n",
      "- Angular_L\n",
      "- Angular_R\n",
      "\n",
      "FPN Network Regions:\n",
      "- Frontal_Mid_L\n",
      "- Frontal_Mid_R\n",
      "- Parietal_Inf_L\n",
      "- Parietal_Inf_R\n",
      "\n",
      "Salience Network Regions:\n",
      "- Insula_L\n",
      "- Insula_R\n",
      "- Cingulum_Ant_L\n",
      "- Cingulum_Ant_R\n",
      "\n",
      "Limbic Network Regions:\n",
      "- Amygdala_L\n",
      "- Amygdala_R\n",
      "- Hippocampus_L\n",
      "- Hippocampus_R\n"
     ]
    }
   ],
   "source": [
    "# Create a reverse mapping from index to region name\n",
    "idx_to_region = {v: k for k, v in pseudo_idx_aal.items()}\n",
    "\n",
    "# Function to map indices to region names\n",
    "def map_indices_to_regions(indices):\n",
    "    return [idx_to_region[idx] for idx in indices]\n",
    "\n",
    "# Map each network's indices to region names\n",
    "network_regions = {\n",
    "    'Auditory': map_indices_to_regions(pseudo_idx_auditory),\n",
    "    'Visual': map_indices_to_regions(pseudo_idx_visual),\n",
    "    'Motor': map_indices_to_regions(pseudo_idx_motor),\n",
    "    'DMN': map_indices_to_regions(pseudo_idx_dmn),\n",
    "    'FPN': map_indices_to_regions(pseudo_idx_fpn),\n",
    "    'Salience': map_indices_to_regions(pseudo_idx_salience),\n",
    "    'Limbic': map_indices_to_regions(pseudo_idx_limbic)\n",
    "}\n",
    "\n",
    "# Print the regions for each network\n",
    "for network, regions in network_regions.items():\n",
    "    print(f\"\\n{network} Network Regions:\")\n",
    "    for region in regions:\n",
    "        print(f\"- {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masker object created.\n"
     ]
    }
   ],
   "source": [
    "# Create masker object, bandpass filter and smooth the data\n",
    "smoothing_fwhm = 2\n",
    "high_pass = 0.008\n",
    "low_pass = 0.24\n",
    "t_r = 2\n",
    "\n",
    "masker = create_masker(aal_img, smoothing_fwhm=smoothing_fwhm, high_pass=high_pass, low_pass=low_pass, \n",
    "                       t_r=t_r, standardize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Extract & Save HC timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fMRI data for subject sub-005C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-006C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-007C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-009C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-013C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-014C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-015C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-016C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-017C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-018C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-019C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-020C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-021C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-024C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-025C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-026C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-027C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-028C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-029C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-030C : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-031C : (97, 115, 97, 312)\n"
     ]
    }
   ],
   "source": [
    "ts_hc = []\n",
    "task = 'pds'\n",
    "\n",
    "for group in [subjects_hc]:\n",
    "    fmri_imgs = load_fmri_data(data_dir, group, task)\n",
    "    regressors = load_regressors(data_dir, group, task)\n",
    "    # Extract time series data\n",
    "    ts_group = extract_timeseries(masker, fmri_imgs, regressors)\n",
    "    if group == subjects_hc:\n",
    "        ts_hc.extend(ts_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to store the timeseries for each subject and region\n",
    "\n",
    "ts_hc_dict = {}\n",
    "for i in range(len(subjects_hc)):\n",
    "    subject = subjects_hc[i]\n",
    "    auditory_timeseries = ts_hc[i][:, pseudo_idx_auditory]\n",
    "    visual_timeseries = ts_hc[i][:, pseudo_idx_visual]\n",
    "    motor_timeseries = ts_hc[i][:, pseudo_idx_motor]\n",
    "    dmn_timeseries = ts_hc[i][:, pseudo_idx_dmn]\n",
    "    fpn_timeseries = ts_hc[i][:, pseudo_idx_fpn]\n",
    "    salience_timeseries = ts_hc[i][:, pseudo_idx_salience]\n",
    "    limbic_timeseries = ts_hc[i][:, pseudo_idx_limbic]\n",
    "    ts_hc_dict[subject] = {\n",
    "        'auditory': auditory_timeseries,\n",
    "        'visual': visual_timeseries,\n",
    "        'motor': motor_timeseries,\n",
    "        'dmn': dmn_timeseries,\n",
    "        'fpn': fpn_timeseries,\n",
    "        'salience': salience_timeseries,\n",
    "        'limbic': limbic_timeseries\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store data\n",
    "subjects = []\n",
    "regions = []\n",
    "all_timeseries = []\n",
    "\n",
    "# Extract data from dictionary\n",
    "for subject, region_dict in ts_hc_dict.items():\n",
    "    for region, ts in region_dict.items():\n",
    "        # Transpose timeseries from (312, N) to (N, 312)\n",
    "        ts_transposed = ts.T\n",
    "        \n",
    "        # For each individual timeseries in the region\n",
    "        for single_ts in ts_transposed:\n",
    "            subjects.append(subject)\n",
    "            regions.append(region)\n",
    "            all_timeseries.append(single_ts)\n",
    "\n",
    "# Convert timeseries list to a numpy array for easier handling\n",
    "all_timeseries_array = np.array(all_timeseries)\n",
    "\n",
    "# Create column names for timepoints\n",
    "timepoint_cols = [f'timepoint_{i+1}' for i in range(all_timeseries_array.shape[1])]\n",
    "\n",
    "# Create the DataFrame all at once\n",
    "df = pd.DataFrame(\n",
    "    np.column_stack([subjects, regions, all_timeseries_array]),\n",
    "    columns=['subject', 'region'] + timepoint_cols\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('timeseries_data_wide.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for MDD and SZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fMRI data for subject sub-003P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-004P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-005P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-007P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-008P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-010P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-014P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-020P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-031P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-032P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-033P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-035P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-037P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-042P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-046P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-048P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-051P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-052P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-066P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-067P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-075P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-015P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-016P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-018P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-019P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-023P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-024P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-030P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-039P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-041P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-043P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-045P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-047P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-049P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-050P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-055P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-056P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-061P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-069P : (97, 115, 97, 312)\n",
      "Shape of fMRI data for subject sub-071P : (97, 115, 97, 312)\n"
     ]
    }
   ],
   "source": [
    "ts_mdd = []\n",
    "ts_sz = []\n",
    "task = 'pds'\n",
    "\n",
    "# already extracted HC\n",
    "for group in [subjects_mdd, subjects_sz]:\n",
    "    fmri_imgs = load_fmri_data(data_dir, group, task)\n",
    "    regressors = load_regressors(data_dir, group, task)\n",
    "    # Extract time series data\n",
    "    ts_group = extract_timeseries(masker, fmri_imgs, regressors)\n",
    "    if group == subjects_mdd:\n",
    "        ts_mdd.extend(ts_group)\n",
    "    elif group == subjects_sz:\n",
    "        ts_sz.extend(ts_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to store the timeseries for each subject and region\n",
    "\n",
    "ts_mdd_dict = {}\n",
    "for i in range(len(subjects_mdd)):\n",
    "    subject = subjects_mdd[i]\n",
    "    auditory_timeseries = ts_mdd[i][:, pseudo_idx_auditory]\n",
    "    visual_timeseries = ts_mdd[i][:, pseudo_idx_visual]\n",
    "    motor_timeseries = ts_mdd[i][:, pseudo_idx_motor]\n",
    "    dmn_timeseries = ts_mdd[i][:, pseudo_idx_dmn]\n",
    "    fpn_timeseries = ts_mdd[i][:, pseudo_idx_fpn]\n",
    "    salience_timeseries = ts_mdd[i][:, pseudo_idx_salience]\n",
    "    limbic_timeseries = ts_mdd[i][:, pseudo_idx_limbic]\n",
    "    ts_mdd_dict[subject] = {\n",
    "        'auditory': auditory_timeseries,\n",
    "        'visual': visual_timeseries,\n",
    "        'motor': motor_timeseries,\n",
    "        'dmn': dmn_timeseries,\n",
    "        'fpn': fpn_timeseries,\n",
    "        'salience': salience_timeseries,\n",
    "        'limbic': limbic_timeseries\n",
    "    }\n",
    "\n",
    "ts_sz_dict = {}\n",
    "for i in range(len(subjects_sz)):\n",
    "    subject = subjects_sz[i]\n",
    "    auditory_timeseries = ts_sz[i][:, pseudo_idx_auditory]\n",
    "    visual_timeseries = ts_sz[i][:, pseudo_idx_visual]\n",
    "    motor_timeseries = ts_sz[i][:, pseudo_idx_motor]\n",
    "    dmn_timeseries = ts_sz[i][:, pseudo_idx_dmn]\n",
    "    fpn_timeseries = ts_sz[i][:, pseudo_idx_fpn]\n",
    "    salience_timeseries = ts_sz[i][:, pseudo_idx_salience]\n",
    "    limbic_timeseries = ts_sz[i][:, pseudo_idx_limbic]\n",
    "    ts_sz_dict[subject] = {\n",
    "        'auditory': auditory_timeseries,\n",
    "        'visual': visual_timeseries,\n",
    "        'motor': motor_timeseries,\n",
    "        'dmn': dmn_timeseries,\n",
    "        'fpn': fpn_timeseries,\n",
    "        'salience': salience_timeseries,\n",
    "        'limbic': limbic_timeseries\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store data\n",
    "subjects = []\n",
    "regions = []\n",
    "all_timeseries = []\n",
    "\n",
    "# Extract data from dictionary\n",
    "for subject, region_dict in ts_mdd_dict.items():\n",
    "    for region, ts in region_dict.items():\n",
    "        # Transpose timeseries from (312, N) to (N, 312)\n",
    "        ts_transposed = ts.T\n",
    "        \n",
    "        # For each individual timeseries in the region\n",
    "        for single_ts in ts_transposed:\n",
    "            subjects.append(subject)\n",
    "            regions.append(region)\n",
    "            all_timeseries.append(single_ts)\n",
    "\n",
    "# Convert timeseries list to a numpy array for easier handling\n",
    "all_timeseries_array = np.array(all_timeseries)\n",
    "\n",
    "# Create column names for timepoints\n",
    "timepoint_cols = [f'timepoint_{i+1}' for i in range(all_timeseries_array.shape[1])]\n",
    "\n",
    "# Create the DataFrame all at once\n",
    "df = pd.DataFrame(\n",
    "    np.column_stack([subjects, regions, all_timeseries_array]),\n",
    "    columns=['subject', 'region'] + timepoint_cols\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('timeseries_data_wide_mdd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store data\n",
    "subjects = []\n",
    "regions = []\n",
    "all_timeseries = []\n",
    "\n",
    "# Extract data from dictionary\n",
    "for subject, region_dict in ts_sz_dict.items():\n",
    "    for region, ts in region_dict.items():\n",
    "        # Transpose timeseries from (312, N) to (N, 312)\n",
    "        ts_transposed = ts.T\n",
    "        \n",
    "        # For each individual timeseries in the region\n",
    "        for single_ts in ts_transposed:\n",
    "            subjects.append(subject)\n",
    "            regions.append(region)\n",
    "            all_timeseries.append(single_ts)\n",
    "\n",
    "# Convert timeseries list to a numpy array for easier handling\n",
    "all_timeseries_array = np.array(all_timeseries)\n",
    "\n",
    "# Create column names for timepoints\n",
    "timepoint_cols = [f'timepoint_{i+1}' for i in range(all_timeseries_array.shape[1])]\n",
    "\n",
    "# Create the DataFrame all at once\n",
    "df = pd.DataFrame(\n",
    "    np.column_stack([subjects, regions, all_timeseries_array]),\n",
    "    columns=['subject', 'region'] + timepoint_cols\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('timeseries_data_wide_sz.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
